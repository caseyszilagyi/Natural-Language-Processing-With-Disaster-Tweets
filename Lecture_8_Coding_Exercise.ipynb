{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VkXxwOsdO2TU"
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries for training and visualization\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8-9rw0MKXrMA",
    "outputId": "bc219b92-238b-4cfb-975d-19815bb679f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla P100-PCIE-16GB'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see that you are connected to a GPU\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDw80WDnOpQU"
   },
   "outputs": [],
   "source": [
    "# Defining a normalization function for our data using the transforms library.\n",
    "\n",
    "# transforms.ToTensor() to scales values in the RGB channels typically (between \n",
    "# 0 and 255) to values between 0 and 1. We only have one channel in MNIST since\n",
    "# it is a grayscale image.\n",
    "\n",
    "# transforms.Normalize() normalizes the inputs to the given mean and std dev.\n",
    "# Since we only have one channel, specify the mean and std dev as 1-D vectors.\n",
    "mean = (0.5,)\n",
    "std_dev = (0.5,)\n",
    "\n",
    "normalization_transforms = [transforms.ToTensor(), \n",
    "                            transforms.Normalize(mean, std_dev)]\n",
    "\n",
    "# Composing all of our desired transforms into a single object we'll use when\n",
    "# loading out dataset.\n",
    "transform = transforms.Compose(normalization_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlgkpdvCPZ_r"
   },
   "outputs": [],
   "source": [
    "# Defining hyper-parameters and other values used by our model.\n",
    "\n",
    "# Size of the batch our network sees. Batch size dictates how many examples the \n",
    "# model \"sees\" before computing updates (or backpropagation). \n",
    "batch_size = 100\n",
    "\n",
    "# The percentage of our training dataset that will be used for validation \n",
    "# during training.\n",
    "validation_split = .2\n",
    "\n",
    "# Below are parameters for the shuffling of the dataset. We specify the random\n",
    "# seed explicitly so your data-split is the same as this example.\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "\n",
    "# Loading and create pytorch dataset objects for our training and test sets.\n",
    "\n",
    "# MNIST is a traditional dataset that exists in the PyTorch library, however,\n",
    "# if you are loading your own dataset there will be additional code here to \n",
    "# do so. We will see an example of how to do this in a future lecture.\n",
    "\n",
    "train_set = datasets.MNIST('PATH_TO_STORE_TRAINSET', download=True, \\\n",
    "                           train=True, transform=transform)\n",
    "test_set = datasets.MNIST('PATH_TO_STORE_TESTSET', download=True, \\\n",
    "                          train=False, transform=transform)\n",
    "\n",
    "# train_set = datasets.FashionMNIST('PATH_TO_STORE_TRAINSET', download=True, \\\n",
    "#                           train=True, transform=transform)\n",
    "# test_set = datasets.FashionMNIST('PATH_TO_STORE_TESTSET', download=True, \\\n",
    "#                           train=False, transform=transform)\n",
    "\n",
    "# Create validation split by taking a percentage of the training set:\n",
    "dataset_size = len(train_set)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "# Shuffle the dataset to increase generalization and speed training\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Use the SubsetRandomSampler to randomly sample the training dataset for \n",
    "# training and validation data. We will feed this into the dataloader below.\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# Create dataloader objects - will be used during training and inference\n",
    "# to iterate over the data.\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, \\\n",
    "                                           sampler=train_sampler)\n",
    "val_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, \\\n",
    "                                         sampler=val_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, \\\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBI4LMzUTpx1"
   },
   "outputs": [],
   "source": [
    "# Verify we've loaded the number of training and testing samples we expect.\n",
    "print(len(train_set), len(test_set))\n",
    "\n",
    "# Let's visualize data from our validation to make sure it's loaded correctly.\n",
    "# Each time this is run, a random sample will be viewed.\n",
    "dataiter = iter(val_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Making sure the dimensions of the image and label tensors are as expected\n",
    "# is critical, since otherwise you'll be faced with a slew of dimension errors.\n",
    "\n",
    "# We should see the image shape listed as [batch_size, channels, height, width]\n",
    "# and label shape as [batch_size,]\n",
    "print(\"Image shape: \", images.shape, \"Label shape: \", labels.shape)\n",
    "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lhoZ6F8HUI9D"
   },
   "outputs": [],
   "source": [
    "# Here we are going to create our neural network class by inheiriting the \n",
    "# nn.Module class. The main functions to notice are the initialization function \n",
    "# __init__() and forward propagation function forward().\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "  # We initialize our neural net by defining the input size, number of nodes\n",
    "  # in hidden layers, and the total number of classes we are detecting.\n",
    "  def __init__(self, num_classes):\n",
    "\n",
    "    # IMPORTANT: This is often forgotten, but make sure to make a super call.\n",
    "    super(Net, self).__init__()\n",
    "\n",
    "    pass\n",
    "  \n",
    "  # Below we construct the output of the forward propagation pass of the neural\n",
    "  # net using the layers and activation functions defined in the Net constructor.\n",
    "  def forward(self, x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rcLI1_bblcQ7"
   },
   "outputs": [],
   "source": [
    "# Create a neural network object with the specified number of input neurons,\n",
    "# hidden neurons, and output neurons (or total classes)\n",
    "\n",
    "net = Net(784, 16, 10)\n",
    "\n",
    "# We use cross-entropy loss with the Adam optimizer. No need to understand what\n",
    "# these two mean just yet, we will go over cross-entropy soon and the Adam \n",
    "# optimizer in a later lecture.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1YPL2YuI9Azm"
   },
   "outputs": [],
   "source": [
    "# Function for getting accuracy, adapted from: \n",
    "# https://towardsdatascience.com/a-simple-starter-guide-to-build-a-neural-network-3c2cf07b8d7c\n",
    "\n",
    "def get_accuracy(loader, my_net):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for images, labels in loader:\n",
    "      images = Variable(images)\n",
    "      outputs = my_net(images)\n",
    "      _, predicted = torch.max(outputs.data, 1)  \n",
    "      total += labels.size(0)               \n",
    "      correct += (predicted == labels).sum()\n",
    "\n",
    "  return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PhfFX57Ulsj7"
   },
   "outputs": [],
   "source": [
    "# Here we create our training loop, which runs for the number of epochs\n",
    "# specified below. \n",
    "\n",
    "# 1 Epoch represents one entire pass through your training dataset, so 20 epochs\n",
    "# means that your model will see each data point ~20 times during training.\n",
    "num_epochs = 5\n",
    "\n",
    "loss_tracker = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  # Initialize random value for loss just for displaying purposes\n",
    "  loss = torch.tensor([100])\n",
    "\n",
    "  # Using the tqdm for nice training visuals\n",
    "  progress_bar = tqdm.notebook.tqdm(train_loader, ncols=1000)\n",
    "\n",
    "  # We load a batch of images and their corresponding labels here and continue\n",
    "  # until we trained on all batches.\n",
    "  for i, (images, labels) in enumerate(progress_bar):\n",
    "    # Convert torch tensor to a vector of size 784 in order to send it to input\n",
    "    # layer\n",
    "    images = Variable(images)\n",
    "    labels = Variable(labels)\n",
    "\n",
    "    if i == 0:\n",
    "      print(images.size(0))\n",
    "\n",
    "    # Clear the gradients before performing backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    # Perform the forward pass - this call of net calls the forward() fn\n",
    "    outputs = net(images)\n",
    "    # Compute loss on the output of the forward pass and desired label\n",
    "    loss = criterion(outputs, labels)\n",
    "    # Compute the gradients with respect to the loss function\n",
    "    loss.backward()      \n",
    "    # Update the weights in the neural network using the optimizer/backprop\n",
    "    optimizer.step()\n",
    "\n",
    "    # Track losses for plotting later\n",
    "    loss_tracker.append(loss.data)                                  \n",
    "\n",
    "    # Visualization code\n",
    "    if (i+1) % 100 == 0 or (i+1) == len(train_loader):   \n",
    "      progress_bar.set_description('Epoch [%d/%d], Step [%d/%d], Val Acc: %d, Training Loss: %.4f'\n",
    "              %(epoch+1, num_epochs, i+1, len(train_loader), \\\n",
    "                get_accuracy(val_loader, net), loss.data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_PflR18lwGd"
   },
   "outputs": [],
   "source": [
    "# Print the training and test accuracy\n",
    "train_acc = get_accuracy(train_loader, net)\n",
    "test_acc = get_accuracy(test_loader, net)\n",
    "\n",
    "print('Accuracy of the network on the 60K train images: %d %%' % (train_acc))\n",
    "print('Accuracy of the network on the 10K test images: %d %%' % (test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lLwzEfFiCWOf"
   },
   "outputs": [],
   "source": [
    "# Plot the loss over time\n",
    "plt.plot(loss_tracker)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Step Number\")\n",
    "plt.title(\"Loss over time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KY1qkKJeaXOm"
   },
   "outputs": [],
   "source": [
    "# Let's visualize where the model is making bad predictions and get an idea of \n",
    "# why that's happening\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1)\n",
    "\n",
    "correct = 0\n",
    "misclassified_images = []\n",
    "misclassified_labels = []\n",
    "misclassified_preds = []\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images)\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)  \n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "    if predicted != labels:\n",
    "      misclassified_images.append(images.view(1, 28, 28))\n",
    "      misclassified_labels.append(labels)\n",
    "      misclassified_preds.append(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "p8WtKA3WdUwe",
    "outputId": "4f8d7b0b-157f-4035-8fe7-93d4cf421b47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label:  tensor([7])\n",
      "Prediction:  tensor([9])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Keep running this cell to see randomly chosen images that the model misclassified\n",
    "# in the testing set.\n",
    "rand_idx = np.random.randint(len(misclassified_images))\n",
    "plt.imshow(misclassified_images[rand_idx].numpy().squeeze(), cmap='gray_r');\n",
    "print(\"Actual Label: \", misclassified_labels[rand_idx])\n",
    "print(\"Prediction: \", misclassified_preds[rand_idx])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lecture #8 - Coding Exercise",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
